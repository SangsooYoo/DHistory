# AI의 종류
Narrow AI : 하나의 기능에 대해서만 성능을 발휘.
현재의 모든 AI는 Narrow AI에 해당됨

Super UI : 

# 분석방법
회귀분석
분류분석

# 퍼셉트론(뉴런)
1. 가중치[w] : 입력신호가 결과에 주는 영향력을 조절하는 변수
2. 편향[b/바이어스] : 퍼셉트론이 얼마나 쉽게 활성화 하느냐를 조정하는 변수
3. 활성화 함수[f(x)] : 입력신호의 총합을 확인해 출력신호를 결정하는 함수
F(∑ Xi * Wi + b)

# 다층 퍼셉트론
3 레이어라고 하면 
입력데이터또한 1개의 래이어로 인정.
1개의 Hidden layer
1개의 output layer

입력레이어의 값들은 은닉층의 각 퍼셉트론으로 전달되어  활성함수를 통해 계산한 값을 출력레이어로 전달됨

분석 방법에 따라서 AI의 디자인 방법이 다름
회귀분석 : 활성함수로 항등함수를 사용
X1 * W1 + X2 * W2 +..
예측 하고자 하는 정보의 개수 만큼 output layer에 퍼셉트론 배치
분류분석 : 
* 활성화 함수로 스프트맥스 함수 (확율 분포) 사용 output layer의 모든 값을 합하면 1이됨.
* 분류하고자 하는 카테고리의 종류만큼 output layer에 퍼셉트론 배치

#깊은층
층을 깊게 할수록 더 복잡한 문제에 대해서 대응 가능
이전층에서 학습한 특징을 조합하여 더 높은 차원의 문제에 대응
> 예제) 입력 -> 선을 찾음 -> 선을 기반으로 객체를 찾음 -> 객체를 기반으로 사물을 찾음

비선형성
선형함수 (y=ax+b)는 여러번 결합해도 선형성을 갖게됨
비선형성을 추가하면 여러변 연산시 더 복잡한 문제를 해결 가능
입력 (x) -> P1 (ax + b) -> P2 (ax+b) * a2 + b2 == ax + b의 형태가 됨. 

활성함수
    선형함수(ax+b)의 결과에 활성함수를 이용하여 비선형성을 확보
    활성함수 종류 : Step function, Sigmoid, Relu, Than, etc..
    Sigmoid : 1/1+e^-x
    Relu : max(0,x)
    Leaky Relu : max(0.1,x)
    tanh : tanh(x)


선형성 + 깊은층 => 층을 아무리 샇아도 결국 선형성 층 한개를 찾는것과 동일함. 
비선형성 + 깊은층 => 단계적으로 문제해결을 하기 위한 접근이 가능해짐

최적화 (Optimizatino)
문제를 풀기위한 최적의 가중치를 찾아가는 과정
사람이 지식을 습득하는 과정과 유사해 학습(Learning) 이라고 함

효율적인 학습을 위해 필요 한 것은?
* 학습이 더 필요한 부분을 알기위한 지표인 점수가 필요함
* 손실함수
    * 딥러닝 모델 학습시 학습의 지표가 되는 함수
    * 모델의 추론 결과와 실제 정답 간의 차이를 의미하는 함수
    * 목적함수(Objective function), 비용 함수(Cost Function)이라고도 부름
    * 대표적 손실함수 : 평균 제곱 오차(MSE, mean square error)
    1/n * ∑(Yi-Y`i) ^ 2

* 오차역전파법 (backpropagation)
    * 가중치의 변화에 따른 오차(error, 손실함수의 값)의 변화를 기울기 형태로 계산
    * 오차를 가장 최소화 하는 Weight와 Bias값을 찾아내는 과정
    * 예측을 수행한 모델의 모든 가중치들에 대하여 미분을 통해 기울기 계산
    * 계산그래프 방식을 이용하여 각 가중치의 오차에 대한 기울기를 계산

* 경사하강법 (Gradient descent) 
    * 정답과 추론값의 차이를 줄이기 위해 가중치 값을 업데이트 하는 전략
    * 오차역전파를 통한 계산한 미분(가중치와 손실함수 간의 영향도) 값을 이용
    * 기울기를 방향 삼아 기울기가 0이 되는 지점을 향해 가중치 값을 업데이트
    * Wk+1 = Wk - n*(∂L/∂W) : n 학습율, ∂L/∂W 가중치와 손실함수간의 영향
    W가 점차 0이되는 시점이 발생함

# 딥러닝 모델의 공간적 의미
* 뉴런 학습의 공간적 의미

# 다양한 모델과 다양한 성능지표
* 머신러닝에서 어떠한 문제를 해결하는 시스템을 모델이라고 부름
* 문제의 유형에 다라 성능을 측정할 수 있는 지표가 다름
* Regression(회귀분석)을 위한 지표
    * MSE
    * MAE
    * MSPE : 정답과 예측 값 차의 제곱 가중합
    * R Square : MSE/데이터 셋의 분산
    * Adjusted R Square : R square값에 input feature의 개수 패널티 가중치를 준 값
    가장 좋은 성능지표 범용으로 사용가능
* Classification(분류)
    * Precision-Recall
        * test data set 학습을 위해 준비된 데이터
        * positive : test데이터 셋의 positive셋은 분류에 해당하는 그룹
        * negative : test데이터 셋의 negative셋은 분류에 해당하지 않는 그룹
        * predict data set 모델에 의해서 판단된 데이터 
        * true : predict set에서 그 예상 결과가 test셋과 일치 하는 그룹
        * false : predict set에서 그 예상 결과가 test셋과 일치하지 않는 그룹
    * ROC-AUC
    * Accuracy
        * 정합도, 모델이 정답을 정답으로 오답을 오답으로 선택하는 가를 보여주는 지표
        * (T.P + T.N) / (T.P + T.N + F.P + F.N) 
    * Log-Loss
    * Precision
        * 정밀도 모델에서 정답이 아닌 것을 얼마나 잘 걸러 내는가를 보여주는 지표
        * T.P / (T.P + F.P) : 모델에 의해서 Positive로 판단된 결과중 실제 test set에 해당하는 비율
    * Recall
        * 재현율 모델에서 실제 정답을 얼마나 많이 선택하는 가를 보여주는 지표
        * T.P / (T.P + F.N) : 테스트 셋에서 Positive중 실제 맞춘 비율
* Recall이 중요한 경우
    * Test데이터가 Positive인 데이터를 Negative로 잘못 하게되면 업무상 큰 영향이 발생하는 경우
    * Classificaiton의 경우 대부분이 검추랗고자 하는 경우 Minor
    * 대부분의 케이스에서 Precision보다 중요한 지표
    * ex, 보험사기 검출, 금융사기 검출, 어뷰징 검출, 질병 검출
* Precision이 중요한 경우
    * Test 데이터가 Negative인 데이터를 Positive로 잘못 하게 되면 업무상 큰 영향이 발생하는 경우
    * ex) 스팸 메일 분류, 추천 시스템

# 결측치
수집한 데이터중 일부가 수집된 적이 없거나 기록의 누락으로 빈 값을 갖는 경우를 칭함
결측치를 어떻게 보완하는가에 따라서 ML을 위한 데이터의 유효성에 영향을 줌

## 결측치를 찾아 처리하는 방법
* 데이터에 대한 충분한 이해 필요
* 결측치의 유뮤 확인
* 결측치 발생의 원인을 추정
* 제거할 것인가? 대체할 것인가 결정
* 대체 값은 어떻게 구할 것인가

# ML 과정
https://colab.research.google.com/drive/1Ku_ikyOb_fVskUxu1hoNuXUbo-XZMs4L#scrollTo=2iorrUU1XtDt 참조
1. 데이터의 획득
2. 데이터 전처리
    1. 탐색적 분석 : 컬럼별 데이터 분석  
    범주형 데이터에 대한 접근 :  
        데이터의 종류 검토 df.unique()  
        데이터의 빈도 df.value_counts()  
        데이터의 비율 df.value_counts(normalize=True)  
    수치 데이터에 대한 접근 :  
        수치형 데이터가 object로 저장되었을 경우  unique()/describe()/isnull()통한 결측치 검사를 통해서 해당 데이터가 정말 범주형이 맞는지 분석   
        수치형이 맞다면 결측치로 처리함  
        astype()을 이용하여 형변환  
    결측치의 보정 :  
        dropna(), fillna() 이용해서 보정
        loc속성을 통해서 조건을 만족하는 값들을 np.nan으로 할당하여 초기화  
        결측치가 너무 많으면 학습할 데이터가 유실되므로 범주형의 경우 임의의 범주를 추가하는 등의 방법으로 보정함  
        결측치가 작다면, 버리거나 평균등으로 대체가능
3. ㅇㅇㅇ  
    1. 이상치의 제거  
    중간 값에서 Q1 - 1.5 * IQR ~ Q3 - 1.5 * IQR의 범위를 넘어가는 값들을 이상치 라고함 (평균분포에서 많이 벗어난 값들)
    상하위 25%씩을 제거
    df.describe()를 통해 획득한 값에서 min/max값과 평균값을 비교했을 때 그 값의 차가 클때 이상치로 판단 가능하다 
    **이외의 다른 방법들이 존재함** 추가 공부 필요
    
---------------------------------------------
# ML의 유형

## 지도학습
* 정답라벨이 주어진 상태에서 학습하는 방식
    * 라벨링된 학습데이터 준비
    * 학습진행하여 모델완성
    * 학습에 사용되지 않은 임의 데이터로 모델의 검증
* 분류분석
    * 예측하고자 하는 값이 범주형 데이터일 경우
    * 이미지, 문서의 분류
* 회귀분석
    * 예측하고자 하는 값이 연속형 데이터
    * 주식 가격 예측, 부동산 가격 예측

## 비지도학습
* 정답라벨이 없는 상태에서 학습하는 방식
    * 별도 라벨링 없이 데이터 준비
    * 학습진행 군집화 학습
    * 임의의 데이터 입력시 해당 데이터가 어떤 군집에 해당하는지 패턴을 찾는 학습방식
* 군집분석 Clustering
    * 데이터의 특징, 구조 등을 통해 유사한 특성을 가진 데이터끼리 그룹화 하는 과정  
    유사어, 유사 이미지, 고객분류, 추천시스템등 다양한 분야에 사용됨
* 준 지도학습 Semi-Supervised learning
    * 라벨이 있는 데이터와 라벨이 없는 데이터를 모두 사용하여 학습하는 방식
## 강화학습
* 모델이 목표를 달성할 수 있도록 보상을 기반으로 학습하는 방식
* 특정 목표를 딜성하는데 최선의 전략을 선택하도록 학습됨
* 사람이 할수 있는 다양한 분야에서 활용됨  
체스게임, 알파고, 자율주행 등

--------------------------------------------
# ML의 주요 프로세스
## 문제정의
* 해결하려는 문제를 명확하게 정의
* 문제 해결을 위한 알고리즘을 선정하는 단계
* 해결할 문제(데이터 특성)에 따라 적절한 알고리즘을 선택
## 데이터수집
* 학습/검증에 사용할 데이터를 수집하는 단계
* 데이터는 학습된 모델의 품질을 결정하는 중요 요소
    * 충분히 큰데이터.
    * 대표성을 가지는 데이터
    * 고품질의 데이터
*6
데이터전처리
특징추출
학습
검증
* 데이터 셋의 분할
    * 트레이닝 데이터 셋  
    머신러닝 모델의 학습에 사용되는 데이터 셋
    * validation 데이터 셋  
    학습된 머신러닝 모델의 성능을 평가하는데 사용되는 데이터셋으로 모델 개선의 지표가 됨
    * Testing 데이터 셋  
    학습 및 개선된 머신러닝 모델을 최종평가하는 데이터 셋
## 데이터 전처리 
* 데이터 품질을 결정하는 중요한 단계로 데이터를 정제하는 과정
* 데이터 전처리를 위한 다양한 기법이 존재 
    * 누락된 데이터 찾아 처리
    * 이상값 찾아 처리 
    * 데이터의 스케일 맞추기 
    * 데이터의 인코딩
    * 라벨링
    * 이미지, 음성등과 같은 비정형 데이터의 경우 다양한 전처리 작업이 선행됨. 
        * 사진의 크기, 명암, 중요 부분 잘라내기
        * 음성의 노이즈제거, 단위시간별 분할
        * 자연어의 경우 오타 수정등
* 가장 오래 걸리고 어려운 작업
* 도메인에 대한 전문지식, 데이터에 대한 이해가 중요함
## 특징 추출
* Feature란  
모델에 학습시킬 데이터의 특성을 의미하는 용어로, 독립변수들을 지칭함. (x값)
* Class란  
모델을 통해 판단하고자 예측 하고자하는 정답 값으로 종속변수를 지칭함 ( 결과, 정답값)
* Feature가 많다고 하여 결과 값이 좋아지는 것이 아님
* 데이터에 대한 도메인 지식을 활용하여 특징을 만들어내는 과정
* Feature Engineering이라고도 불림
    * Feature selection
    * Feature Extraction
    * Feature learning
* 모델 성능에 미치는 영향이 매우 큼
## 학습과 검증
* 전처리/ 특징 추출작업이 완료된 학습데이터 셋을 입력으로 
* 모델이 최적화 될때까지 학습이 반복됨
* 학습을 얼만큼 반복할 것인가 ?
* 모델이 최적화 되고 있음을 어떻게 판단할 것인가.?
* 학습에 노출된 적이 없는 검증 데이터 셋을 이용하여 모델 검증
* 문제의 특성에 따라서 다양한 검증지표 사용
    * 분류 : 정확도, 재현율, 정밀도...
    * 회귀 : MSE, MAE...
----------------------------------------------
# 싸이킷 런 라이브러리 
## 파이선 기반의 머신러닝 활용
* numphy : 행렬, 대규모 다차원 데이터의 분석
* pandas : 행,렬의 2차원 데이터 분석을 위한 라이브러리
* matplotlib, seaborn: 데이터 시각화 라이브러리
* scipy : 기술 통계를 위한 라이브러리
* statsmodels: 통계분석 라이브러리
* scikit-learn : 머신러닝 라이브러리
## 사이킷 런 라이브러리
* 파이썬 기반의 대표적 머신러닝 라이브러리
* 머신러닝을 위한 다양한 알고리즘 프레임워크, api제공
* 오랜기간 검증됨
